{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch metadata and properties on the Wiki Loves Monument photos dataset**\n",
    "\n",
    "API Source:\n",
    "https://commons.wikimedia.org/wiki/Commons:API/MediaWiki\n",
    "https://commons.wikimedia.org/w/api.php?action=help&modules=query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the MongoDB instance**\n",
    "\n",
    "The script requires the presence of a database *wikilm* and a collection *photos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db_name = db_client[\"wikilm\"]\n",
    "db_collection = db_name[\"photos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL_BASEURL = \"https://commons.wikimedia.org/w/api.php?\"\n",
    "API_QUERY_PARAMS = {\n",
    "    'action':'query',\n",
    "    \"pageids\":\"\",\n",
    "    \"prop\":\"categories|imageinfo|coordinates|templates|linkshere|links|globalusage\",\n",
    "    \"format\":\"json\",\n",
    "    \"iiprop\":\"metadata\"\n",
    "}\n",
    "\n",
    "def get_title(title):\n",
    "    if not title.startswith(\"File:\"):\n",
    "        return \"File:\"+title\n",
    "    return title\n",
    "\n",
    "def retrieve_info(pids):\n",
    "    r_json = None\n",
    "    new_collection = []\n",
    "    if len(pids)>0:\n",
    "        r_json = get_json_response(pids)\n",
    "    if r_json:\n",
    "        new_collection = parse_json_response(r_json)\n",
    "    save_json_response(new_collection)\n",
    "\n",
    "def get_json_response(pids):\n",
    "    API_QUERY_PARAMS['pageids'] = \"|\".join([str(x) for x in pids])\n",
    "    r =requests.get(API_URL_BASEURL, params=API_QUERY_PARAMS)\n",
    "    r_json = r.json()\n",
    "    return r_json\n",
    "\n",
    "def parse_json_response(r_json):\n",
    "    photos = []\n",
    "    if 'query' in r_json:    \n",
    "        for current in r_json['query']['pages']:\n",
    "            r_json['query']['pages'][current]['_id']=int(current)\n",
    "            photos.append(r_json['query']['pages'][current])\n",
    "    return photos\n",
    "    \n",
    "def save_json_response(new_collection):\n",
    "    if len(new_collection)>0:\n",
    "        db_collection.insert_many(new_collection, ordered=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ../data/wlm_data_2010.tsv.bz2\n",
      "retrieved 12581 photos\n",
      "10000\n",
      "\n",
      "loading ../data/wlm_data_2011.tsv.bz2\n",
      "retrieved 86722 photos\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "cannot convert float NaN to integer\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "DATA_FOLDER = '../data/'\n",
    "BATCH_N_ITEMS = 50\n",
    "inputfile = \"wlm_data_%d.tsv.bz2\"\n",
    "\n",
    "years = range(2010, 2012)\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    ids_already_fetched = set(db_collection.find().distinct('_id'))\n",
    "    current = DATA_FOLDER+inputfile %year\n",
    "    \n",
    "    print('loading %s' %current)\n",
    "    photos = pd.read_csv(current, sep=\"\\t\", error_bad_lines=False) \\\n",
    "        .drop_duplicates(subset=['page_id']) \\\n",
    "        .reset_index()\n",
    "    print('retrieved %d photos' %photos.shape[0])\n",
    "    candidates = []\n",
    "    count = 0\n",
    "    \n",
    "    for i, p in photos.iterrows():\n",
    "        try:\n",
    "            pid = int(p['page_id'])\n",
    "            if not (pid in ids_already_fetched):\n",
    "                \n",
    "                candidates.append(pid)\n",
    "                count+=1\n",
    "                \n",
    "                if count%BATCH_N_ITEMS==0:\n",
    "                    sleep(randint(2, 4))\n",
    "                    retrieve_info(candidates)\n",
    "                    candidates.clear()\n",
    "        \n",
    "            if i>0 and i%10000==0:\n",
    "                print('fetched: ', i)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            \n",
    "    if len(candidates)>0:\n",
    "        retrieve_info(candidates)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
